{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 230,
   "metadata": {},
   "outputs": [],
   "source": [
    "from nba_api.stats.endpoints import commonplayerinfo\n",
    "from nba_api.stats.endpoints import leaguegamelog\n",
    "from nba_api.stats.endpoints import boxscoreplayertrackv2\n",
    "from nba_api.stats.endpoints import teamgamelog\n",
    "from nba_api.stats.static import teams\n",
    "import pandas as pd\n",
    "import requests\n",
    "import time"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Step 1: Utility Stuff\n",
    "\n",
    "We're going to get the IDs of every team and store them. Later, we can cross reference the IDs with the `list_of_teams` to figure out which team was which"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 228,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{1610612737: 'Atlanta Hawks',\n",
       " 1610612738: 'Boston Celtics',\n",
       " 1610612739: 'Cleveland Cavaliers',\n",
       " 1610612740: 'New Orleans Pelicans',\n",
       " 1610612741: 'Chicago Bulls',\n",
       " 1610612742: 'Dallas Mavericks',\n",
       " 1610612743: 'Denver Nuggets',\n",
       " 1610612744: 'Golden State Warriors',\n",
       " 1610612745: 'Houston Rockets',\n",
       " 1610612746: 'Los Angeles Clippers',\n",
       " 1610612747: 'Los Angeles Lakers',\n",
       " 1610612748: 'Miami Heat',\n",
       " 1610612749: 'Milwaukee Bucks',\n",
       " 1610612750: 'Minnesota Timberwolves',\n",
       " 1610612751: 'Brooklyn Nets',\n",
       " 1610612752: 'New York Knicks',\n",
       " 1610612753: 'Orlando Magic',\n",
       " 1610612754: 'Indiana Pacers',\n",
       " 1610612755: 'Philadelphia 76ers',\n",
       " 1610612756: 'Phoenix Suns',\n",
       " 1610612757: 'Portland Trail Blazers',\n",
       " 1610612758: 'Sacramento Kings',\n",
       " 1610612759: 'San Antonio Spurs',\n",
       " 1610612760: 'Oklahoma City Thunder',\n",
       " 1610612761: 'Toronto Raptors',\n",
       " 1610612762: 'Utah Jazz',\n",
       " 1610612763: 'Memphis Grizzlies',\n",
       " 1610612764: 'Washington Wizards',\n",
       " 1610612765: 'Detroit Pistons',\n",
       " 1610612766: 'Charlotte Hornets'}"
      ]
     },
     "execution_count": 228,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "list_of_teams = teams.get_teams()\n",
    "all_team_ids = []\n",
    "dict_ids_to_name = dict()\n",
    "for team_obj in list_of_teams:\n",
    "    all_team_ids.append(team_obj['id'])\n",
    "    dict_ids_to_name[team_obj['id']] = team_obj['full_name']\n",
    "dict_ids_to_name"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Takes a string formatted as \"x:xx\" or \"xx:xx\" and returns the equivalent number of seconds as an int... will be useful for filtering players based on playing time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def str_to_mins(inp):\n",
    "    lst = inp.split(\":\")\n",
    "    sec = int(lst[0])*60 + int(lst[1])\n",
    "    return sec"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Step 2: Storing Individual Games + Winning/Losing Players\n",
    "We are going to create an empty dataframe where we are going to store everything. Our columns are going to be `game_id`, `winning_team_id`, `winning_team_players`, and `losing_team_players`. To build our basic model where we one-hot encode players names and try to see if our model can predict at better than 50% accuracy who is going to win, this information will suffice."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 231,
   "metadata": {},
   "outputs": [],
   "source": [
    "record = pd.DataFrame(columns=['game_id', 'winning_team_id', 'winning_team_players', 'losing_team_players'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now, we need to iterate through every season from 1997-1998 to 2018-2019, check every single team's game log (accessed through the `TeamGameLog` endpoint), and insert the game into `record` if the team won. By only inserting the game if the team won, we ensure that we don't duplicate any entries. When considering a given game, we will use the `BoxScorePlayerTrackV2` endpoint, which takes in a `GAME_ID` and returns the boxscore, to get the list of players who played at least 3 minutes on each team. Afterwards, we'll save to a pickle file so that we can access the data easily.\n",
    "\n",
    "### WARNING: Takes very very long to run... stored in a pickle file so you can just unpack it"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 245,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2016 Atlanta Hawks\n",
      "Analyzed games in 55.47568930000125 seconds\n",
      "2016 Boston Celtics\n",
      "Analyzed games in 69.32438439999532 seconds\n",
      "2016 Cleveland Cavaliers\n",
      "Analyzed games in 65.60309780000534 seconds\n",
      "2016 New Orleans Pelicans\n",
      "Analyzed games in 43.83745690000069 seconds\n",
      "2016 Chicago Bulls\n",
      "Analyzed games in 55.30768100000569 seconds\n",
      "2016 Dallas Mavericks\n",
      "Analyzed games in 45.270042499993 seconds\n",
      "2016 Denver Nuggets\n",
      "Analyzed games in 53.763859800004866 seconds\n",
      "2016 Golden State Warriors\n",
      "Analyzed games in 90.65585510000528 seconds\n",
      "2016 Houston Rockets\n",
      "Analyzed games in 70.22965439999825 seconds\n",
      "2016 Los Angeles Clippers\n",
      "Analyzed games in 67.40251020000142 seconds\n",
      "2016 Los Angeles Lakers\n",
      "Analyzed games in 34.48479590000352 seconds\n",
      "2016 Miami Heat\n",
      "Analyzed games in 53.67464579999796 seconds\n",
      "2016 Milwaukee Bucks\n",
      "Analyzed games in 55.54073829999834 seconds\n",
      "2016 Minnesota Timberwolves\n",
      "Analyzed games in 39.5967793000018 seconds\n",
      "2016 Brooklyn Nets\n",
      "Analyzed games in 28.4038670000009 seconds\n",
      "2016 New York Knicks\n",
      "Analyzed games in 41.91557070000272 seconds\n",
      "2016 Orlando Magic\n",
      "Analyzed games in 37.05449619999854 seconds\n",
      "2016 Indiana Pacers\n",
      "Analyzed games in 55.13785790000111 seconds\n",
      "2016 Philadelphia 76ers\n",
      "Analyzed games in 35.60367599999881 seconds\n",
      "2016 Phoenix Suns\n",
      "Analyzed games in 30.817450199989253 seconds\n",
      "2016 Portland Trail Blazers\n",
      "Analyzed games in 53.53337010000541 seconds\n",
      "2016 Sacramento Kings\n",
      "Analyzed games in 42.51826430000074 seconds\n",
      "2016 San Antonio Spurs\n",
      "Analyzed games in 78.13977449999948 seconds\n",
      "2016 Oklahoma City Thunder\n",
      "Analyzed games in 59.66307699999015 seconds\n",
      "2016 Toronto Raptors\n",
      "Analyzed games in 65.68490759999258 seconds\n",
      "2016 Utah Jazz\n",
      "Analyzed games in 65.08503100000962 seconds\n",
      "2016 Memphis Grizzlies\n",
      "Analyzed games in 54.774407400007476 seconds\n",
      "2016 Washington Wizards\n",
      "Analyzed games in 67.35188890001155 seconds\n",
      "2016 Detroit Pistons\n",
      "Analyzed games in 47.522133999998914 seconds\n",
      "2016 Charlotte Hornets\n",
      "Analyzed games in 46.142231599995284 seconds\n",
      "2017 Atlanta Hawks\n",
      "Analyzed games in 31.039787200003047 seconds\n",
      "2017 Boston Celtics\n",
      "Analyzed games in 70.52799859999504 seconds\n",
      "2017 Cleveland Cavaliers\n",
      "Analyzed games in 63.21002520000911 seconds\n",
      "2017 New Orleans Pelicans\n",
      "Analyzed games in 63.243760799989104 seconds\n",
      "2017 Chicago Bulls\n",
      "Analyzed games in 34.86286860000109 seconds\n",
      "2017 Dallas Mavericks\n",
      "Analyzed games in 30.506223599993973 seconds\n",
      "2017 Denver Nuggets\n",
      "Analyzed games in 60.4190804999962 seconds\n",
      "2017 Golden State Warriors\n",
      "Analyzed games in 77.50972560000082 seconds\n",
      "2017 Houston Rockets\n",
      "Analyzed games in 83.59579279999889 seconds\n",
      "2017 Los Angeles Clippers\n",
      "Analyzed games in 65.7299328000081 seconds\n",
      "2017 Los Angeles Lakers\n",
      "Analyzed games in 57.53858590000891 seconds\n",
      "2017 Miami Heat\n",
      "Analyzed games in 69.2079756000021 seconds\n",
      "2017 Milwaukee Bucks\n",
      "Analyzed games in 68.71418080000149 seconds\n",
      "2017 Minnesota Timberwolves\n",
      "Analyzed games in 73.77069219999248 seconds\n",
      "2017 Brooklyn Nets\n",
      "Analyzed games in 44.98521050000272 seconds\n",
      "2017 New York Knicks\n",
      "Analyzed games in 46.067069199998514 seconds\n",
      "2017 Orlando Magic\n",
      "Analyzed games in 39.90804449999996 seconds\n",
      "2017 Indiana Pacers\n",
      "Analyzed games in 75.61981930000184 seconds\n",
      "2017 Philadelphia 76ers\n",
      "Analyzed games in 82.34506619999593 seconds\n",
      "2017 Phoenix Suns\n",
      "Analyzed games in 32.98415240000759 seconds\n",
      "2017 Portland Trail Blazers\n",
      "Analyzed games in 76.79221159999724 seconds\n",
      "2017 Sacramento Kings\n",
      "Analyzed games in 45.45734039999661 seconds\n",
      "2017 San Antonio Spurs\n",
      "Analyzed games in 73.36863689999154 seconds\n",
      "2017 Oklahoma City Thunder\n",
      "Analyzed games in 75.54152159999649 seconds\n",
      "2017 Toronto Raptors\n",
      "Analyzed games in 94.38795140000002 seconds\n",
      "2017 Utah Jazz\n",
      "Analyzed games in 79.19727930000226 seconds\n",
      "2017 Memphis Grizzlies\n",
      "Analyzed games in 34.562817600002745 seconds\n",
      "2017 Washington Wizards\n",
      "Analyzed games in 71.53254400000151 seconds\n",
      "2017 Detroit Pistons\n",
      "Analyzed games in 59.94490139999834 seconds\n",
      "2017 Charlotte Hornets\n",
      "Analyzed games in 52.52385779999895 seconds\n",
      "2018 Atlanta Hawks\n",
      "Analyzed games in 43.44183759999578 seconds\n",
      "2018 Boston Celtics\n",
      "Analyzed games in 72.28674099998898 seconds\n",
      "2018 Cleveland Cavaliers\n",
      "Analyzed games in 30.62542539999413 seconds\n",
      "2018 New Orleans Pelicans\n",
      "Analyzed games in 56.263269199989736 seconds\n",
      "2018 Chicago Bulls\n",
      "Analyzed games in 35.16961189999711 seconds\n",
      "2018 Dallas Mavericks\n",
      "Analyzed games in 52.259730699996 seconds\n",
      "2018 Denver Nuggets\n",
      "Analyzed games in 85.94253159999789 seconds\n",
      "2018 Golden State Warriors\n",
      "Analyzed games in 92.14661329999217 seconds\n",
      "2018 Houston Rockets\n",
      "Analyzed games in 87.91454680000606 seconds\n",
      "2018 Los Angeles Clippers\n",
      "Analyzed games in 77.42901550000533 seconds\n",
      "2018 Los Angeles Lakers\n",
      "Analyzed games in 59.16941200000292 seconds\n",
      "2018 Miami Heat\n",
      "Analyzed games in 61.51828740000201 seconds\n",
      "2018 Milwaukee Bucks\n",
      "Analyzed games in 81.57227319999947 seconds\n",
      "2018 Minnesota Timberwolves\n",
      "Analyzed games in 46.85612479998963 seconds\n",
      "2018 Brooklyn Nets\n",
      "Analyzed games in 56.008665200002724 seconds\n",
      "2018 New York Knicks\n",
      "Analyzed games in 21.435266500004218 seconds\n",
      "2018 Orlando Magic\n",
      "Analyzed games in 57.37055029999465 seconds\n",
      "2018 Indiana Pacers\n",
      "Analyzed games in 62.04469949999475 seconds\n",
      "2018 Philadelphia 76ers\n",
      "Analyzed games in 66.2920962000062 seconds\n",
      "2018 Phoenix Suns\n",
      "Analyzed games in 25.33996539999498 seconds\n",
      "2018 Portland Trail Blazers\n",
      "Analyzed games in 69.20316479999747 seconds\n",
      "2018 Sacramento Kings\n",
      "Analyzed games in 49.44503829999303 seconds\n",
      "2018 San Antonio Spurs\n",
      "Analyzed games in 61.72192169999471 seconds\n",
      "2018 Oklahoma City Thunder\n",
      "Analyzed games in 62.36860090000846 seconds\n",
      "2018 Toronto Raptors\n",
      "Analyzed games in 74.85504860000219 seconds\n",
      "2018 Utah Jazz\n",
      "Analyzed games in 63.417057300001034 seconds\n",
      "2018 Memphis Grizzlies\n",
      "Analyzed games in 44.673555000001215 seconds\n",
      "2018 Washington Wizards\n",
      "Analyzed games in 44.44238969999424 seconds\n",
      "2018 Detroit Pistons\n",
      "Analyzed games in 55.02261099999305 seconds\n",
      "2018 Charlotte Hornets\n",
      "Analyzed games in 50.943370799999684 seconds\n"
     ]
    }
   ],
   "source": [
    "import timeit\n",
    "for year in range(2016,2019):\n",
    "    for team_id in all_team_ids:\n",
    "        \n",
    "        print(year, dict_ids_to_name[team_id])\n",
    "        \n",
    "        # a little code block to retry if the NBA site tries to block us\n",
    "        max_retries = 10\n",
    "        for _ in range(max_retries):\n",
    "            try:\n",
    "                gamelog_for_season = teamgamelog.TeamGameLog(team_id, year, timeout=15)\n",
    "                break\n",
    "            except:\n",
    "                pass\n",
    "        \n",
    "        try:\n",
    "            gamelog_for_season\n",
    "        except NameError:\n",
    "            break #raise NameError(f\"Tried {max_retries} times but couldn't get gamelog\")\n",
    "                    \n",
    "        gamelog_df = gamelog_for_season.get_data_frames()[0] #return statement is a list, we want the first element\n",
    "\n",
    "        start = timeit.default_timer()\n",
    "        for row in gamelog_df.itertuples():\n",
    "            if row.WL == \"W\": #remember, only want the winning team so we don't duplicate anything\n",
    "                time.sleep(.7)\n",
    "                \n",
    "                ministart = timeit.default_timer()\n",
    "                # a little code block to retry if the NBA site tries to block us\n",
    "                max_retries = 5\n",
    "                for _ in range(max_retries):\n",
    "                    try:\n",
    "                        bx = boxscoreplayertrackv2.BoxScorePlayerTrackV2(row.Game_ID, timeout=15)\n",
    "                        break\n",
    "                    except:\n",
    "                        pass\n",
    "                    \n",
    "                try:\n",
    "                    bx\n",
    "                except NameError:\n",
    "                    break #raise NameError(f\"Tried {max_retries} times but couldn't get gamelog\")\n",
    "                ministop = timeit.default_timer()\n",
    "                if ministop-ministart > 10:\n",
    "                    print(\"Fetched boxscore #\", row.Index,\"in\",ministop-ministart,\"seconds\")\n",
    "                \n",
    "                #rest of code, here we are separating the boxscore into the winning team players and losing team players\n",
    "                players = bx.get_data_frames()[0]\n",
    "                team_list = players['TEAM_ID'].unique()\n",
    "                players_dict = dict()\n",
    "                \n",
    "                for team in team_list:\n",
    "                    players_dict[team] = set()\n",
    "                \n",
    "                for innerrow in players.itertuples():\n",
    "                    if str_to_mins(innerrow.MIN) >= 3*60:\n",
    "                        players_dict[innerrow.TEAM_ID].add(innerrow.PLAYER_NAME)\n",
    "                        \n",
    "                \n",
    "                #definitions for our insertion into the dataframe\n",
    "                game_id = row.Game_ID\n",
    "                winning_team_id = team_id\n",
    "                winning_team_players = players_dict[winning_team_id]\n",
    "                losing_team_players = players_dict[next(iter(set(players_dict.keys()) - {winning_team_id}))]\n",
    "                record = record.append({'game_id': game_id, \\\n",
    "                                        'winning_team_id': winning_team_id, \\\n",
    "                                        'winning_team_players': winning_team_players, \\\n",
    "                                        'losing_team_players': losing_team_players}, ignore_index=True)\n",
    "        stop = timeit.default_timer()\n",
    "        print(\"Analyzed games in\",stop-start,\"seconds\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 248,
   "metadata": {},
   "outputs": [],
   "source": [
    "record = record.drop_duplicates(subset=\"game_id\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 249,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "record.to_pickle(\"one_hot_model_dataset\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Step 3: Data Exploration\n",
    "Now, we can import the pickled dataset and start using it for data exploration. This is a relatively uninteresting dataset, since we only have the names of players. However, one useful thing to do is to store the set of all unique players. We'll use it later when trying to encode our data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 251,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>game_id</th>\n",
       "      <th>winning_team_id</th>\n",
       "      <th>winning_team_players</th>\n",
       "      <th>losing_team_players</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0029701183</td>\n",
       "      <td>1610612737</td>\n",
       "      <td>{Tyrone Corbin, Drew Barry, Anthony Miller, Ch...</td>\n",
       "      <td>{Terry Mills, Rex Walters, Voshon Lenard, Mark...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0029701167</td>\n",
       "      <td>1610612737</td>\n",
       "      <td>{Tyrone Corbin, Anthony Miller, Christian Laet...</td>\n",
       "      <td>{B.J. Armstrong, Dell Curry, Donald Royal, Ant...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0029701142</td>\n",
       "      <td>1610612737</td>\n",
       "      <td>{Tyrone Corbin, Anthony Miller, Christian Laet...</td>\n",
       "      <td>{Theo Ratliff, Joe Smith, Benoit Benjamin, All...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0029701130</td>\n",
       "      <td>1610612737</td>\n",
       "      <td>{Tyrone Corbin, Anthony Miller, Christian Laet...</td>\n",
       "      <td>{God Shammgod, Ledell Eackles, Ben Wallace, Ch...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0029701115</td>\n",
       "      <td>1610612737</td>\n",
       "      <td>{Tyrone Corbin, Anthony Miller, Christian Laet...</td>\n",
       "      <td>{B.J. Armstrong, Dell Curry, Glen Rice, Matt G...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      game_id winning_team_id  \\\n",
       "0  0029701183      1610612737   \n",
       "1  0029701167      1610612737   \n",
       "2  0029701142      1610612737   \n",
       "3  0029701130      1610612737   \n",
       "4  0029701115      1610612737   \n",
       "\n",
       "                                winning_team_players  \\\n",
       "0  {Tyrone Corbin, Drew Barry, Anthony Miller, Ch...   \n",
       "1  {Tyrone Corbin, Anthony Miller, Christian Laet...   \n",
       "2  {Tyrone Corbin, Anthony Miller, Christian Laet...   \n",
       "3  {Tyrone Corbin, Anthony Miller, Christian Laet...   \n",
       "4  {Tyrone Corbin, Anthony Miller, Christian Laet...   \n",
       "\n",
       "                                 losing_team_players  \n",
       "0  {Terry Mills, Rex Walters, Voshon Lenard, Mark...  \n",
       "1  {B.J. Armstrong, Dell Curry, Donald Royal, Ant...  \n",
       "2  {Theo Ratliff, Joe Smith, Benoit Benjamin, All...  \n",
       "3  {God Shammgod, Ledell Eackles, Ben Wallace, Ch...  \n",
       "4  {B.J. Armstrong, Dell Curry, Glen Rice, Matt G...  "
      ]
     },
     "execution_count": 251,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "record = pd.read_pickle(\"one_hot_model_dataset\")\n",
    "record.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 252,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The # of unique players that have played at least 3 minutes in a game from the 1997-98 season to the 2018-19 season is 2023\n"
     ]
    }
   ],
   "source": [
    "#Number of unique players\n",
    "all_players = set()\n",
    "for index, row in record.iterrows():\n",
    "    all_players.update(row[\"winning_team_players\"], row[\"losing_team_players\"])\n",
    "all_players = list(all_players)\n",
    "all_players = sorted(all_players)\n",
    "print(\"The # of unique players that have played at least 3 minutes in a game from the 1997-98 season to the 2018-19 season is\", len(all_players))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Step 4: Data Processing\n",
    "Cool! Now we have our `record` which is a table that contains all the data we need. Unfortunately, a machine learning algorithm cannot take this as an input. We need to [one-hot encode](https://en.wikipedia.org/wiki/One-hot) our data, secifically, using the Python methods describe [here](https://machinelearningmastery.com/how-to-one-hot-encode-sequence-data-in-python/). This means we will have to create a column for every player, whose value will be 1 if the player was in the game and 0 otherwise.\n",
    "\n",
    "However, here we run into our first issue. If we just create a single column for each player, the algorithm will have no way of knowing who was on what team. Therefore, we need to create two columns for each player (e.g., for LeBron James, we have columns `LeBronJames_A` and `LeBronJames_B`). So, now we can make one of the teams A, and one of the teams B. However, we need to make sure that we don't, for example, encode the winning team as team A always. Otherwise, the ML algorithm will think that being team A is what makes you win, instead of seeing how individual players affect the chance of winning.\n",
    "\n",
    "One way we can solve this issue is by creating two entries for each game. We can encode (Winning Team -> A, Losing Team -> B) + make it a positive training example (i.e. 1), and then make an entry for the reverse, encoding (Winning Team -> B, Losing Team -> A) + make it a negative training example (i.e. 0). This way, the algorithm won't correlate being team A or team B with winning. This way, when we use the algorithm for inference, we can log the teams in arbitrary order without having to worry about who is A or who is B."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A useful method. We will require the condensed version of players names a lot, so makes sense to pay the overhead and do it now so that we can access it in constant time instead of having to do expensive string operations at each step"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 253,
   "metadata": {},
   "outputs": [],
   "source": [
    "name_to_condensed_dict = dict()\n",
    "for player in all_players:\n",
    "    player_name_condensed = player.replace(\" \", \"\")\n",
    "    name_to_condensed_dict[player] = player_name_condensed"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we're going to add columns to `ml_record` for every single player indicating whether they played on team A or B, plus a column for the outcome of the game (1 if team A won, 0 if team B won)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 254,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>A.C.Green_A</th>\n",
       "      <th>A.C.Green_B</th>\n",
       "      <th>A.J.Bramlett_A</th>\n",
       "      <th>A.J.Bramlett_B</th>\n",
       "      <th>A.J.Guyton_A</th>\n",
       "      <th>A.J.Guyton_B</th>\n",
       "      <th>AJHammons_A</th>\n",
       "      <th>AJHammons_B</th>\n",
       "      <th>AJPrice_A</th>\n",
       "      <th>AJPrice_B</th>\n",
       "      <th>...</th>\n",
       "      <th>ZhaireSmith_B</th>\n",
       "      <th>ZhouQi_A</th>\n",
       "      <th>ZhouQi_B</th>\n",
       "      <th>ZoranDragic_A</th>\n",
       "      <th>ZoranDragic_B</th>\n",
       "      <th>ZoranPlaninic_A</th>\n",
       "      <th>ZoranPlaninic_B</th>\n",
       "      <th>ZydrunasIlgauskas_A</th>\n",
       "      <th>ZydrunasIlgauskas_B</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>52131</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>52132</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>52133</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>52134</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>52135</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>52136 rows Ã— 4047 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      A.C.Green_A A.C.Green_B A.J.Bramlett_A A.J.Bramlett_B A.J.Guyton_A  \\\n",
       "0             NaN         NaN            NaN            NaN          NaN   \n",
       "1             NaN         NaN            NaN            NaN          NaN   \n",
       "2             NaN         NaN            NaN            NaN          NaN   \n",
       "3             NaN         NaN            NaN            NaN          NaN   \n",
       "4             NaN         NaN            NaN            NaN          NaN   \n",
       "...           ...         ...            ...            ...          ...   \n",
       "52131         NaN         NaN            NaN            NaN          NaN   \n",
       "52132         NaN         NaN            NaN            NaN          NaN   \n",
       "52133         NaN         NaN            NaN            NaN          NaN   \n",
       "52134         NaN         NaN            NaN            NaN          NaN   \n",
       "52135         NaN         NaN            NaN            NaN          NaN   \n",
       "\n",
       "      A.J.Guyton_B AJHammons_A AJHammons_B AJPrice_A AJPrice_B  ...  \\\n",
       "0              NaN         NaN         NaN       NaN       NaN  ...   \n",
       "1              NaN         NaN         NaN       NaN       NaN  ...   \n",
       "2              NaN         NaN         NaN       NaN       NaN  ...   \n",
       "3              NaN         NaN         NaN       NaN       NaN  ...   \n",
       "4              NaN         NaN         NaN       NaN       NaN  ...   \n",
       "...            ...         ...         ...       ...       ...  ...   \n",
       "52131          NaN         NaN         NaN       NaN       NaN  ...   \n",
       "52132          NaN         NaN         NaN       NaN       NaN  ...   \n",
       "52133          NaN         NaN         NaN       NaN       NaN  ...   \n",
       "52134          NaN         NaN         NaN       NaN       NaN  ...   \n",
       "52135          NaN         NaN         NaN       NaN       NaN  ...   \n",
       "\n",
       "      ZhaireSmith_B ZhouQi_A ZhouQi_B ZoranDragic_A ZoranDragic_B  \\\n",
       "0               NaN      NaN      NaN           NaN           NaN   \n",
       "1               NaN      NaN      NaN           NaN           NaN   \n",
       "2               NaN      NaN      NaN           NaN           NaN   \n",
       "3               NaN      NaN      NaN           NaN           NaN   \n",
       "4               NaN      NaN      NaN           NaN           NaN   \n",
       "...             ...      ...      ...           ...           ...   \n",
       "52131           NaN      NaN      NaN           NaN           NaN   \n",
       "52132           NaN      NaN      NaN           NaN           NaN   \n",
       "52133           NaN      NaN      NaN           NaN           NaN   \n",
       "52134           NaN      NaN      NaN           NaN           NaN   \n",
       "52135           NaN      NaN      NaN           NaN           NaN   \n",
       "\n",
       "      ZoranPlaninic_A ZoranPlaninic_B ZydrunasIlgauskas_A ZydrunasIlgauskas_B  \\\n",
       "0                 NaN             NaN                 NaN                 NaN   \n",
       "1                 NaN             NaN                 NaN                 NaN   \n",
       "2                 NaN             NaN                 NaN                 NaN   \n",
       "3                 NaN             NaN                 NaN                 NaN   \n",
       "4                 NaN             NaN                 NaN                 NaN   \n",
       "...               ...             ...                 ...                 ...   \n",
       "52131             NaN             NaN                 NaN                 NaN   \n",
       "52132             NaN             NaN                 NaN                 NaN   \n",
       "52133             NaN             NaN                 NaN                 NaN   \n",
       "52134             NaN             NaN                 NaN                 NaN   \n",
       "52135             NaN             NaN                 NaN                 NaN   \n",
       "\n",
       "      label  \n",
       "0       NaN  \n",
       "1       NaN  \n",
       "2       NaN  \n",
       "3       NaN  \n",
       "4       NaN  \n",
       "...     ...  \n",
       "52131   NaN  \n",
       "52132   NaN  \n",
       "52133   NaN  \n",
       "52134   NaN  \n",
       "52135   NaN  \n",
       "\n",
       "[52136 rows x 4047 columns]"
      ]
     },
     "execution_count": 254,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cols = []\n",
    "for player in all_players:\n",
    "    player_name_condensed = name_to_condensed_dict[player]\n",
    "    str_a = f\"{player_name_condensed}_A\"\n",
    "    str_b = f\"{player_name_condensed}_B\"\n",
    "    cols.append(str_a)\n",
    "    cols.append(str_b)\n",
    "cols.append(\"label\")\n",
    "ml_record = pd.DataFrame(columns=cols, index=range(record.shape[0]*2))\n",
    "ml_record"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This is another very important block of code. We are going through each game, considering each player, and changing the appropriate column for that player to 1. Additionally, we are creating a second training example with the opposite result."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "offset = record.shape[0]\n",
    "for row in record.itertuples():\n",
    "    index = row.Index\n",
    "    winning_team_players = row.winning_team_players\n",
    "    losing_team_players = row.losing_team_players\n",
    "    if index%100 == 0:\n",
    "        print(f\"iteratation {index} of {offset}: {round(index/offset*100,2)}%\")\n",
    "    #create the first training example, which has a result of 1 and the winning players on team A\n",
    "    a_players = winning_team_players\n",
    "    b_players = losing_team_players\n",
    "    for player in a_players:\n",
    "        player_name_condensed = name_to_condensed_dict[player]\n",
    "        str_a = player_name_condensed + \"_A\"\n",
    "        ml_record.at[index, str_a] = 1\n",
    "    for player in b_players:\n",
    "        player_name_condensed = name_to_condensed_dict[player]\n",
    "        str_b = player_name_condensed + \"_B\"\n",
    "        ml_record.at[index, str_b] = 1\n",
    "    ml_record.at[index, \"label\"] = 1\n",
    "    \n",
    "    #create a second training example, which has a result of 0 and the winning players on team B\n",
    "    b_players = winning_team_players\n",
    "    a_players = losing_team_players\n",
    "    for player in a_players:\n",
    "        player_name_condensed = name_to_condensed_dict[player]\n",
    "        str_a = player_name_condensed + \"_A\"\n",
    "        ml_record.at[index+offset, str_a] = 1\n",
    "    for player in b_players:\n",
    "        player_name_condensed = name_to_condensed_dict[player]\n",
    "        str_b = player_name_condensed + \"_B\"\n",
    "        ml_record.at[index+offset, str_b] = 1\n",
    "    ml_record.at[index+offset, \"label\"] = 0"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Ok, so now we're 90% of the way there. Now, we only need to drop the `game_id`, `winning_team_players`, and `losing_team_players` columns (because they're not going into the model), and then we can start preparing the data for training. Additionally, we will pickle this new dataframe since the method above takes a while to finish.  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 256,
   "metadata": {},
   "outputs": [],
   "source": [
    "ml_record = ml_record.fillna(0)\n",
    "ml_record.to_pickle(\"encoded_one_hot_model_dataset\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The extra taining example above unfortunately came out with the blank spaces as `NaN`, but we can replace those with zeroes easily"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 257,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>A.C.Green_A</th>\n",
       "      <th>A.C.Green_B</th>\n",
       "      <th>A.J.Bramlett_A</th>\n",
       "      <th>A.J.Bramlett_B</th>\n",
       "      <th>A.J.Guyton_A</th>\n",
       "      <th>A.J.Guyton_B</th>\n",
       "      <th>AJHammons_A</th>\n",
       "      <th>AJHammons_B</th>\n",
       "      <th>AJPrice_A</th>\n",
       "      <th>AJPrice_B</th>\n",
       "      <th>...</th>\n",
       "      <th>ZhaireSmith_B</th>\n",
       "      <th>ZhouQi_A</th>\n",
       "      <th>ZhouQi_B</th>\n",
       "      <th>ZoranDragic_A</th>\n",
       "      <th>ZoranDragic_B</th>\n",
       "      <th>ZoranPlaninic_A</th>\n",
       "      <th>ZoranPlaninic_B</th>\n",
       "      <th>ZydrunasIlgauskas_A</th>\n",
       "      <th>ZydrunasIlgauskas_B</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>52133</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>52134</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>52135</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>52136</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>52137</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>52138 rows Ã— 4047 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       A.C.Green_A  A.C.Green_B  A.J.Bramlett_A  A.J.Bramlett_B  A.J.Guyton_A  \\\n",
       "0                0            0               0               0             0   \n",
       "1                0            0               0               0             0   \n",
       "2                0            0               0               0             0   \n",
       "3                0            0               0               0             0   \n",
       "4                0            0               0               0             0   \n",
       "...            ...          ...             ...             ...           ...   \n",
       "52133            0            0               0               0             0   \n",
       "52134            0            0               0               0             0   \n",
       "52135            0            0               0               0             0   \n",
       "52136            0            0               0               0             0   \n",
       "52137            0            0               0               0             0   \n",
       "\n",
       "       A.J.Guyton_B  AJHammons_A  AJHammons_B  AJPrice_A  AJPrice_B  ...  \\\n",
       "0                 0            0            0          0          0  ...   \n",
       "1                 0            0            0          0          0  ...   \n",
       "2                 0            0            0          0          0  ...   \n",
       "3                 0            0            0          0          0  ...   \n",
       "4                 0            0            0          0          0  ...   \n",
       "...             ...          ...          ...        ...        ...  ...   \n",
       "52133             0            0            0          0          0  ...   \n",
       "52134             0            0            0          0          0  ...   \n",
       "52135             0            0            0          0          0  ...   \n",
       "52136             0            0            0          0          0  ...   \n",
       "52137             0            0            0          0          0  ...   \n",
       "\n",
       "       ZhaireSmith_B  ZhouQi_A  ZhouQi_B  ZoranDragic_A  ZoranDragic_B  \\\n",
       "0                  0         0         0              0              0   \n",
       "1                  0         0         0              0              0   \n",
       "2                  0         0         0              0              0   \n",
       "3                  0         0         0              0              0   \n",
       "4                  0         0         0              0              0   \n",
       "...              ...       ...       ...            ...            ...   \n",
       "52133              0         0         0              0              0   \n",
       "52134              0         0         0              0              0   \n",
       "52135              0         0         0              0              0   \n",
       "52136              0         0         0              0              0   \n",
       "52137              0         0         0              0              0   \n",
       "\n",
       "       ZoranPlaninic_A  ZoranPlaninic_B  ZydrunasIlgauskas_A  \\\n",
       "0                    0                0                    0   \n",
       "1                    0                0                    0   \n",
       "2                    0                0                    0   \n",
       "3                    0                0                    0   \n",
       "4                    0                0                    0   \n",
       "...                ...              ...                  ...   \n",
       "52133                0                0                    0   \n",
       "52134                0                0                    0   \n",
       "52135                0                0                    0   \n",
       "52136                0                0                    0   \n",
       "52137                0                0                    0   \n",
       "\n",
       "       ZydrunasIlgauskas_B  label  \n",
       "0                        0      1  \n",
       "1                        0      1  \n",
       "2                        0      1  \n",
       "3                        0      1  \n",
       "4                        0      1  \n",
       "...                    ...    ...  \n",
       "52133                    0      0  \n",
       "52134                    0      0  \n",
       "52135                    0      0  \n",
       "52136                    0      0  \n",
       "52137                    0      0  \n",
       "\n",
       "[52138 rows x 4047 columns]"
      ]
     },
     "execution_count": 257,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ml_record = pd.read_pickle(\"encoded_one_hot_model_dataset\")\n",
    "ml_record"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 258,
   "metadata": {},
   "outputs": [],
   "source": [
    "ml_record.to_pickle(\"encoded_one_hot_model_dataset\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We're going to drop some useless columns and turn this into a numpy array, which is what scikit-learn likes as an input"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 259,
   "metadata": {},
   "outputs": [],
   "source": [
    "#convert to final numpy form\n",
    "import numpy as np \n",
    "\n",
    "# Labels are the values we want to predict\n",
    "labels = np.array(ml_record['label'])\n",
    "# Remove the labels column; axis 1 refers to the columns\n",
    "values = ml_record.drop(['label'], axis = 1)\n",
    "# Saving feature names for later use\n",
    "feature_list = list(values.columns)\n",
    "# Convert to numpy array\n",
    "values = np.array(values)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now, finally, we can split this into a training, validation, and testing dataset. We're ready!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 260,
   "metadata": {},
   "outputs": [],
   "source": [
    "#split into training, validation, and testing data\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "X = values\n",
    "y = labels\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    X, y, test_size=0.2, random_state=1)\n",
    "X_train, X_val, y_train, y_val = train_test_split(\n",
    "    X_train, y_train, test_size=0.25, random_state=1) #this gives 20% test, 20% val, 60% train"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 6: Machine Learning - Random Forest\n",
    "We're going to be using scikit-learn's `RandomForestClassifier` for our first attempt. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 269,
   "metadata": {},
   "outputs": [],
   "source": [
    "#here's the magical step! We train the classifier\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "\n",
    "# Instantiate model with 500 decision trees\n",
    "rf = RandomForestClassifier(n_estimators = 500, random_state = 42)\n",
    "# Train the model on training data\n",
    "rf.fit(X_train, y_train);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 270,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['random_forest_week6_model.joblib']"
      ]
     },
     "execution_count": 270,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from joblib import dump\n",
    "dump(rf, 'random_forest_week6_model.joblib')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 271,
   "metadata": {},
   "outputs": [],
   "source": [
    "from joblib import load\n",
    "rf = load('random_forest_week6_model.joblib')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 272,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy:  0.6538166474875335\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.69      0.69      0.69      5807\n",
      "           1       0.61      0.61      0.61      4621\n",
      "\n",
      "    accuracy                           0.65     10428\n",
      "   macro avg       0.65      0.65      0.65     10428\n",
      "weighted avg       0.65      0.65      0.65     10428\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# the next part of the code is to predict based on the validation set and evaluate the performance of the model...\n",
    "# we don't want to use the test set until we're certain that we're absolutely done with tweaking parameters\n",
    "from sklearn import metrics\n",
    "from sklearn.metrics import classification_report\n",
    "\n",
    "y_pred = rf.predict(X_val)\n",
    "# Model Accuracy, how often is the classifier correct?\n",
    "print(\"Accuracy: \",metrics.accuracy_score(y_val, y_pred))\n",
    "print(classification_report(y_val, y_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 7: Machine Learning - Logistic Regression\n",
    "We're going to be using scikit-learn's `LogisticRegression` for our first attempt. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 261,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:   24.2s finished\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "LogisticRegression(max_iter=100000, random_state=0, verbose=1)"
      ]
     },
     "execution_count": 261,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "\n",
    "lr = LogisticRegression(random_state=0, verbose = 1, max_iter=100000)\n",
    "lr.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 262,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['logistic_regression_week6_model.joblib']"
      ]
     },
     "execution_count": 262,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from joblib import dump\n",
    "dump(lr, 'logistic_regression_week6_model.joblib')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 263,
   "metadata": {},
   "outputs": [],
   "source": [
    "from joblib import load\n",
    "lr = load('logistic_regression_week6_model.joblib')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 264,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy:  0.6940928270042194\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.72      0.73      0.73      5807\n",
      "           1       0.66      0.64      0.65      4621\n",
      "\n",
      "    accuracy                           0.69     10428\n",
      "   macro avg       0.69      0.69      0.69     10428\n",
      "weighted avg       0.69      0.69      0.69     10428\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import accuracy_score, classification_report\n",
    "from sklearn import metrics\n",
    "\n",
    "y_pred = lr.predict(X_val)\n",
    "# Model Accuracy, how often is the classifier correct?\n",
    "print(\"Accuracy: \",metrics.accuracy_score(y_val, y_pred))\n",
    "print(classification_report(y_val, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 284,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "list"
      ]
     },
     "execution_count": 284,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "l = list(lr.coef_[0])\n",
    "type(l)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 293,
   "metadata": {},
   "outputs": [],
   "source": [
    "d = dict()\n",
    "for i in range(len(l)):\n",
    "    coef = l[i]\n",
    "    name = feature_list[i]\n",
    "    d[name] = coef"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 299,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.25990892792187387"
      ]
     },
     "execution_count": 299,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "d[\"DraymondGreen_B\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 8: Machine Learning - Naive Bayes\n",
    "We're going to be using scikit-learn's `BernoulliNB` for our first attempt. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 265,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "BernoulliNB(binarize=None)"
      ]
     },
     "execution_count": 265,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.naive_bayes import BernoulliNB\n",
    "\n",
    "bnb = BernoulliNB(binarize = None)\n",
    "bnb.fit(X_train,y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 266,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['bernoulli_naivebayes_week6_model.joblib']"
      ]
     },
     "execution_count": 266,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from joblib import dump\n",
    "dump(bnb, 'bernoulli_naivebayes_week6_model.joblib')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 267,
   "metadata": {},
   "outputs": [],
   "source": [
    "from joblib import load\n",
    "bnb = load('bernoulli_naivebayes_week6_model.joblib')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 268,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy:  0.692270809359417\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.72      0.72      0.72      5807\n",
      "           1       0.65      0.66      0.65      4621\n",
      "\n",
      "    accuracy                           0.69     10428\n",
      "   macro avg       0.69      0.69      0.69     10428\n",
      "weighted avg       0.69      0.69      0.69     10428\n",
      "\n"
     ]
    }
   ],
   "source": [
    "y_pred = bnb.predict(X_val)\n",
    "# Model Accuracy, how often is the classifier correct?\n",
    "print(\"Accuracy: \",metrics.accuracy_score(y_val, y_pred))\n",
    "print(classification_report(y_val, y_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 9: Machine Learning - K-Nearest Neighbors\n",
    "We're going to be using scikit-learn's `svm` for our first attempt. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 273,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "KNeighborsClassifier(n_neighbors=3)"
      ]
     },
     "execution_count": 273,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "\n",
    "neigh = KNeighborsClassifier(n_neighbors=3)\n",
    "neigh.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 274,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['knn_week6_model.joblib']"
      ]
     },
     "execution_count": 274,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from joblib import dump\n",
    "dump(neigh, 'knn_week6_model.joblib')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 275,
   "metadata": {},
   "outputs": [],
   "source": [
    "from joblib import load\n",
    "neigh = load('knn_week6_model.joblib')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 276,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy:  0.61\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.63      0.69      0.65       108\n",
      "           1       0.59      0.52      0.55        92\n",
      "\n",
      "    accuracy                           0.61       200\n",
      "   macro avg       0.61      0.60      0.60       200\n",
      "weighted avg       0.61      0.61      0.61       200\n",
      "\n"
     ]
    }
   ],
   "source": [
    "num_samples = 200\n",
    "y_pred = neigh.predict(X_val[0:num_samples,:])\n",
    "# Model Accuracy, how often is the classifier correct?\n",
    "print(\"Accuracy: \",metrics.accuracy_score(y_val[0:num_samples], y_pred))\n",
    "print(classification_report(y_val[0:num_samples], y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "@webio": {
   "lastCommId": null,
   "lastKernelId": null
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
